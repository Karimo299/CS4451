\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{url}  
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Conference Paper Title*\\
{\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
should not be used}
\thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Otilia Pasculescu}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Western University}\\
London, Ontario \\
opascule@uwo.ca}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Christopher Betancur}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Western University}\\
London, Ontario \\
cbetancu@uwo.ca}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle


\begin{abstract}

\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}


\section{Background \& Related Work}




\section{Methods}

\subsection{Research Objectives}


In this paper we test the following hypothesis:
\begin{quote}
Across the feature subsets we consider, models that combine
image-based MRI features with tabular features achieve higher 
performance in classifying tumour vs non-tumour MRI scans than models
that use a single feature type (tabular-only or image-only), and
for any given feature subset, an RBF-kernel support vector machine (SVM)
performs better the logistic regression model.
\end{quote}

To investigate this hypothesis, we define the following objectives:

\textbf{O1:} Construct seven datasets from the Kaggle Brain Tumor data~\cite{bohajuBrainTumor}
representing different feature subsets: tabular features only
(all 13 features, first-order only, second-order only), image-only features,
image + first-order features, and image + second-order features.

\textbf{O2:} Train and tune logistic regression and RBF-kernel SVM classifiers on
each subset using scikit-learn pipelines with standardization, splitting the
data into training and test sets and optimizing hyperparameters via
cross-validation with grid search.

\textbf{O3:} Compare classification performance across feature subsets and models
using held-out test accuracy and macro-averaged F1-score, and analyze which
feature subset and which model (logistic vs SVM) perform best.


\subsection{Research Methodology}

\subsubsection{Dataset and Preprocessing}

We use the Brain Tumor dataset from Kaggle~\cite{bohajuBrainTumor}, which provides
a CSV file with the precomputed radiomic features and corresponding MRI slice
filenames that those features belong to, along with the raw brain MRI images themselves. 

The raw CSV contains $N = 3762$ samples. We check for and drop any rows with
features taking infinite values, but in this dataset no rows are removed. All feature vectors in the dataset have one to one correspondence to a 2D MRI slice along with a binary label \texttt{Class} where label 1 means that the MRI slice contains a tumor and 0 means the MRI slice does not contain a tumor. For each row in the CSV, it includes an \texttt{Image} identifier (to link row of features to image), the class (tumor or no tumor), and 13 tabular features where the features themselves are divided into two types: 
\paragraph{First-order features.}
\begin{itemize}
    \item Mean
    \item Variance
    \item Standard deviation
    \item Skewness
    \item Kurtosis
\end{itemize}

\paragraph{Second-order (texture) features.}
\begin{itemize}
    \item Contrast
    \item Energy
    \item ASM (angular second moment)
    \item Entropy
    \item Homogeneity
    \item Dissimilarity
    \item Correlation
    \item Coarseness
\end{itemize}


So we now construct seven aligned datasets from the same $N$ samples:

\begin{enumerate}
    \item \textbf{D1: First-order only (tabular)} \\
    Utilize the 5 first-order intensity statistics:
    Mean, Variance, Standard Deviation, Skewness, Kurtosis.

    \item \textbf{D2: Second-order only (tabular)} \\
    Utilize the 8 second-order texture features:
    Contrast, Energy, ASM, Entropy, Homogeneity, Dissimilarity, Correlation, Coarseness.

    \item \textbf{D3: All tabular features} \\
    Utilize all 13 tabular features (first-order + second-order).

    \item \textbf{D4: Image only} \\
    Utilize only the grayscale MRI slice, resized to $64\times64$ and normalized.

    \item \textbf{D5: Image + first-order} \\
    Concatenate image pixels with the 5 first-order features.

    \item \textbf{D6: Image + second-order} \\
    Concatenate image pixels with the 8 second-order features.

    \item \textbf{D7: Image + all tabular features} \\
    Concatenate image pixels with all 13 tabular features.
\end{enumerate}

Each MRI slice is loaded in grayscale, resized to a resolution of $64\times64$,
and then normalized to the range $[0, 1]$. By reducing the size of the original MRI slice from $240\times 240$ to $64\times 64$ we reduce the dimensionality (the number of features we pass into the model) while still retaining the overall structural information needed for tumor classification, following prior work that successfully used small resized MRIs for CNN-based brain tumor classification~\cite{abiwinanda2019, aitamou2022}. In MRI analysis, it is common to normalize the intensities so that MRI machine settings have comparable brightness and contrast before we fit any models~\cite{shinohara2014}.

Let $\mathbf{x}_{\text{img}} \in \mathbb{R}^{4096}$ be the flattened representation
(of length $64\times64$) of the compressed and normalized grayscale MRI slice in pixels and $\mathbf{x}_{\text{tab}} \in \mathbb{R}^{13}$ represent the full tabular feature vector for a given MRI slice. 

For each dataset variant defined above, we construct a single feature vector $\mathbf{x}$ from
these components as follows:
\begin{itemize}
    \item tabular-only variants (D1--D3): $\mathbf{x} \subseteq \mathbf{x}_{\text{tab}}$ where $\mathbf{x}$ can contain all tabular features or a subset.
    \item image-only variant (D4): $\mathbf{x} = \mathbf{x}_{\text{img}}$.
    \item Combined variants (D5--D7):
          \[
              \mathbf{x} =
              \begin{bmatrix}
                  \mathbf{x}_{\text{img}} \\
                  \mathbf{x}'
              \end{bmatrix},
          \]
          where $\mathbf{x}'$ as a subvector of
      $\mathbf{x}_{\text{tab}}$ containing either the 5 first-order features,
      the 8 second-order features, or all 13 tabular features.
\end{itemize}

The goal is to learn a function (model) that, given a feature vector $\mathbf{x}$,
outputs a binary label (a standard supervised binary classification task):
\[
  f : \mathcal{X} \to \{0, 1\},
\]
where $\mathcal{X}$ denotes the space of all feature vectors constructed as above.




\subsubsection{Logistic Regression Model}

\subsubsection{Support Vector Machine Model}

SVMs are margin-based classifiers that finds the decision boundary which maximizes the distance between classes ~\cite{cortes1995support}. This model can represent non-linear decision boundaries by implicitly mapping the input features into a higher-dimensional
space through the kernel function. In this paper, we utilize and SVM with a radial basis function (RBF) kernel~\cite{cortes1995support} as our main model,
implemented using the machine learning library scikit-learn~\cite{pedregosa2011scikit}.

For each of the seven datasets D1--D7 we have defined above each with a unique feature configuration, we then train a separate RBF SVM model on the corresponding feature vectors $\mathbf{x}$. To avoid features with large values dominating the kernel, we standardize
all input features to zero mean and unit variance using a \texttt{StandardScaler} inside a scikit-learn \texttt{Pipeline}.

The RBF SVM has two key hyperparameters:
\begin{enumerate}
    \item Regularization parameter $C$ which controls the trade-off between having a wider margin with more training errors versus fitting the training data more strictly with fewer margin violations.
    \item Kernel width parameter $\gamma$ controls the influence of a single training point.
\end{enumerate}



\subsubsection{Training Procedure and Experimental Design}

For each dataset variant D1--D7, we follow the same training and evaluation
protocol for both logistic regression and SVM models. First, we split the dataset variant into 2 where  80\% is for training and 20\% is for testing. To
preserve the tumour / non-tumour class proportions in each split and making the project reproducible we set a seed for how the data is split:
(\texttt{train\_test\_split(..., test\_size=0.2, stratify=y, random\_state=42)}).



To stabilize optimization and make features comparable in scale, we implement
each classifier as a scikit-learn Pipeline~\cite{pedregosa2011scikit}.For logistic regression, the pipeline uses a median imputer, a
StandardScaler, and a LogisticRegression model with
$\ell_1$ or $\ell_2$ regularisation.For the SVM, the pipeline uses a
StandardScaler and an RBF-kernel SVC classifier.
In both models, the scaler takes and operates on the full feature vector $\mathbf{x}$
(tabular features and, when present, flattened image pixels), ensuring that
each feature dimension has approximately zero mean and unit variance.

Hyperparameters are tuned on the training set using stratified
$k$-fold cross-validation with $k=3$, shuffling, and a fixed
\texttt{random\_state} for reproducible splits. For logistic regression,
the grid search explores different regularization strengths $C$, penalties
($\ell_1$ vs.\ $\ell_2$), and compatible solvers such as (\texttt{liblinear},
\texttt{lbfgs}, \texttt{saga}). 

For the SVM, the grid search varies the
regularization parameter $C$ and the RBF kernel width $\gamma$ over a
small logarithmic grid, where the kernel type is fixed to RBF. 

In both models, we select the hyperparameter combination that maximizes mean
cross-validation accuracy on the training data. After hyperparameter selection, the best model is retrained on the full training set and evaluated once on the held-out test set. For every model (logistic vs.\ SVM) and dataset D1--D7, we report test accuracy and
macro-averaged F1-score, to compare performance across feature subsets and classifiers.


\subsubsection{Evaluation Metrics}


\subsubsection{Threats to Validity and Rationale}





\section{Results}

\section{Conclusions \& Future Work}


\begin{thebibliography}{00}

\bibitem{bohajuBrainTumor}
J.~Bohaju, ``Brain Tumor,'' Kaggle, Jul. 2020, ver.~3. [Online]. Available:
\url{https://www.kaggle.com/datasets/jakeshbohaju/brain-tumor}.
doi: 10.34740/KAGGLE/DSV/955413. [Accessed: Dec. 6, 2025].

\bibitem{abiwinanda2019}
N.~Abiwinanda, M.~Hanif, S.~T.~Hesaputra, A.~Handayani, and T.~R.~Mengko,
``Brain tumor classification using convolutional neural network,''
in \emph{World Congress on Medical Physics and Biomedical Engineering 2018}.
Singapore: Springer, 2019, pp.~183--189.
doi: 10.1007/978-981-10-9035-6\_33.

\bibitem{aitamou2022}
M.~Ait~Amou, H.~Xia, A.~Larhmam, and M.~Alami~El~Filali,
``A novel MRI diagnosis method for brain tumor classification based on deep learning,''
\emph{Healthcare}, vol.~10, no.~3, p.~494, 2022.
doi: 10.3390/healthcare10030494.

\bibitem{shinohara2014}
R.~T.~Shinohara, E.~M.~Sweeney, J.~Goldsmith, N.~Shiee, F.~J.~Mateen, P.~A.~Calabresi,
S.~Jarso, D.~L.~Pham, D.~S.~Reich, and C.~M.~Crainiceanu,
``Statistical normalization techniques for magnetic resonance imaging,''
\emph{NeuroImage: Clinical}, vol.~6, pp.~9--19, 2014.
doi: 10.1016/j.nicl.2014.08.008.


\bibitem{cortes1995support}
C.~Cortes and V.~Vapnik,
``Support-vector networks,''
\emph{Machine Learning}, vol.~20, no.~3, pp.~273--297, 1995.
doi: 10.1007/BF00994018.

\bibitem{pedregosa2011scikit}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
D.~Cournapeau, M.~Brucher, M.~Perrot, and {\'E}.~Duchesnay,
``Scikit-learn: Machine learning in {P}ython,''
\emph{Journal of Machine Learning Research}, vol.~12, pp.~2825--2830, 2011.
[Online]. Available: \url{https://www.jmlr.org/papers/v12/pedregosa11a.html}.



\end{thebibliography}
\vspace{12pt}

\end{document}