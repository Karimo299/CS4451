{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    GridSearchCV,\n",
        "    cross_val_score,\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw dataset shape: (1644, 19)\n",
            "    Image       Mean     Variance  Standard Deviation   Entropy  Skewness  \\\n",
            "0  Image1  23.448517  2538.985627           50.388348  0.651174  1.984202   \n",
            "1  Image2   4.398331   834.853030           28.893823  0.953532  6.495203   \n",
            "\n",
            "    Kurtosis    Contrast    Energy       ASM  Homogeneity  Dissimilarity  \\\n",
            "0   5.421042  181.467713  0.781557  0.610831     0.847033       2.765411   \n",
            "1  43.349355   76.745886  0.972770  0.946281     0.980762       0.548605   \n",
            "\n",
            "   Correlation     Coarseness        PSNR      SSIM       MSE        DC  \\\n",
            "0     0.968576  7.458341e-155   97.974630  0.777011  0.171163  0.303989   \n",
            "1     0.959751  7.458341e-155  110.346597  0.977953  0.009913  0.839019   \n",
            "\n",
            "   Target  \n",
            "0       1  \n",
            "1       1  \n",
            "Removing 98 rows containing infinite values.\n",
            "Clean tabular matrix shape: (1546, 17)\n",
            "Class counts:\n",
            " Target\n",
            "1    1449\n",
            "0      97\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "RAW_DATA_PATH = \"data/bt_dataset_t3.csv\"\n",
        "IMAGES_DIR = \"data/images\"\n",
        "IMAGE_SIZE = (64, 64)\n",
        "\n",
        "# Load raw dataset once so both workflows can reuse it\n",
        "df_raw = pd.read_csv(RAW_DATA_PATH)\n",
        "print(f\"Raw dataset shape: {df_raw.shape}\")\n",
        "print(df_raw.head(2))\n",
        "\n",
        "# Prepare tabular-only view (drop image column)\n",
        "feature_columns = [col for col in df_raw.columns if col not in [\"Image\", \"Target\"]]\n",
        "X_tabular = df_raw[feature_columns].copy()\n",
        "y_tabular = df_raw[\"Target\"].copy()\n",
        "\n",
        "# Remove rows containing +/- inf values\n",
        "inf_mask = np.isinf(X_tabular).any(axis=1)\n",
        "if inf_mask.any():\n",
        "    print(f\"Removing {inf_mask.sum()} rows containing infinite values.\")\n",
        "    X_tabular = X_tabular.loc[~inf_mask].reset_index(drop=True)\n",
        "    y_tabular = y_tabular.loc[~inf_mask].reset_index(drop=True)\n",
        "else:\n",
        "    print(\"No infinite values detected in tabular features.\")\n",
        "\n",
        "# Median-fill any remaining missing values (numeric columns only)\n",
        "X_tabular = X_tabular.fillna(X_tabular.median(numeric_only=True))\n",
        "\n",
        "print(f\"Clean tabular matrix shape: {X_tabular.shape}\")\n",
        "print(\"Class counts:\\n\", y_tabular.value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/Test split sizes: 1236 / 310\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Best params: {'classifier__C': 10, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
            "Mean CV accuracy: 0.9814\n",
            "CV mean ± 2*std: 0.9814 ± 0.0110\n",
            "Test accuracy: 0.9871\n",
            "Confusion matrix (test):\n",
            "[[ 17   2]\n",
            " [  2 289]]\n",
            "\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8947    0.8947    0.8947        19\n",
            "           1     0.9931    0.9931    0.9931       291\n",
            "\n",
            "    accuracy                         0.9871       310\n",
            "   macro avg     0.9439    0.9439    0.9439       310\n",
            "weighted avg     0.9871    0.9871    0.9871       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Logistic regression on tabular features only\n",
        "param_grid_tabular = [\n",
        "    {\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10],\n",
        "        \"classifier__penalty\": [\"l1\"],\n",
        "        \"classifier__solver\": [\"liblinear\", \"saga\"],\n",
        "    },\n",
        "    {\n",
        "        \"classifier__C\": [0.01, 0.1, 1, 10],\n",
        "        \"classifier__penalty\": [\"l2\"],\n",
        "        \"classifier__solver\": [\"lbfgs\", \"saga\"],\n",
        "    },\n",
        "]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"classifier\", LogisticRegression(random_state=42, max_iter=1000)),\n",
        "])\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "X_train_tab, X_test_tab, y_train_tab, y_test_tab = train_test_split(\n",
        "    X_tabular,\n",
        "    y_tabular,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_tabular,\n",
        ")\n",
        "\n",
        "print(f\"Train/Test split sizes: {len(X_train_tab)} / {len(X_test_tab)}\")\n",
        "\n",
        "tabular_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid_tabular,\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=1,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "tabular_search.fit(X_train_tab, y_train_tab)\n",
        "print(f\"Best params: {tabular_search.best_params_}\")\n",
        "print(f\"Mean CV accuracy: {tabular_search.best_score_:.4f}\")\n",
        "\n",
        "best_tabular_model = tabular_search.best_estimator_\n",
        "cv_scores = cross_val_score(best_tabular_model, X_train_tab, y_train_tab, cv=cv, scoring=\"accuracy\")\n",
        "print(f\"CV mean ± 2*std: {cv_scores.mean():.4f} ± {2 * cv_scores.std():.4f}\")\n",
        "\n",
        "y_pred_test = best_tabular_model.predict(X_test_tab)\n",
        "print(f\"Test accuracy: {accuracy_score(y_test_tab, y_pred_test):.4f}\")\n",
        "print(\"Confusion matrix (test):\")\n",
        "print(confusion_matrix(y_test_tab, y_pred_test))\n",
        "print(\"\\nClassification report (test):\")\n",
        "print(classification_report(y_test_tab, y_pred_test, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing 98 rows with inf values for image workflow.\n",
            "Image dataset: 1546 samples, 17 tabular + 4096 image features\n",
            "Class counts:\n",
            " Target\n",
            "1    1449\n",
            "0      97\n",
            "Name: count, dtype: int64\n",
            "Train/Test split sizes (image workflow): 1236 / 310\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Best params (image workflow): {'classifier__C': 1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
            "Mean CV accuracy: 0.9498\n",
            "CV mean ± 2*std: 0.9498 ± 0.0288\n",
            "Test accuracy: 0.9548\n",
            "Confusion matrix (test):\n",
            "[[  9  10]\n",
            " [  4 287]]\n",
            "\n",
            "Classification report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6923    0.4737    0.5625        19\n",
            "           1     0.9663    0.9863    0.9762       291\n",
            "\n",
            "    accuracy                         0.9548       310\n",
            "   macro avg     0.8293    0.7300    0.7693       310\n",
            "weighted avg     0.9495    0.9548    0.9508       310\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def load_and_preprocess_image(image_path, target_size=IMAGE_SIZE):\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        if img.mode != \"L\":\n",
        "            img = img.convert(\"L\")\n",
        "        img = img.resize(target_size)\n",
        "        return (np.array(img, dtype=np.float32) / 255.0).flatten()\n",
        "    except Exception as exc:\n",
        "        print(f\"Failed to load {image_path}: {exc}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def build_image_dataset(df, images_dir=IMAGES_DIR, target_size=IMAGE_SIZE):\n",
        "    feature_cols = [col for col in df.columns if col not in [\"Image\", \"Target\"]]\n",
        "    X_tab = df[feature_cols].copy()\n",
        "    y = df[\"Target\"].copy()\n",
        "\n",
        "    inf_mask = np.isinf(X_tab).any(axis=1)\n",
        "    if inf_mask.any():\n",
        "        print(f\"Removing {inf_mask.sum()} rows with inf values for image workflow.\")\n",
        "        df = df.loc[~inf_mask].reset_index(drop=True)\n",
        "        X_tab = X_tab.loc[~inf_mask].reset_index(drop=True)\n",
        "        y = y.loc[~inf_mask].reset_index(drop=True)\n",
        "\n",
        "    X_tab = X_tab.fillna(X_tab.median(numeric_only=True))\n",
        "\n",
        "    image_features = []\n",
        "    valid_indices = []\n",
        "    for idx, image_name in enumerate(df[\"Image\"]):\n",
        "        if not isinstance(image_name, str):\n",
        "            continue\n",
        "        filename = image_name if image_name.endswith(\".jpg\") else f\"{image_name}.jpg\"\n",
        "        path = os.path.join(images_dir, filename)\n",
        "        if not os.path.exists(path):\n",
        "            print(f\"Missing image: {path}\")\n",
        "            continue\n",
        "        features = load_and_preprocess_image(path, target_size)\n",
        "        if features is not None:\n",
        "            image_features.append(features)\n",
        "            valid_indices.append(idx)\n",
        "\n",
        "    if not image_features:\n",
        "        raise ValueError(\"No images could be processed.\")\n",
        "\n",
        "    X_tab_valid = X_tab.iloc[valid_indices].reset_index(drop=True)\n",
        "    y_valid = y.iloc[valid_indices].reset_index(drop=True)\n",
        "    X_image = np.vstack(image_features)\n",
        "    X_combined = np.hstack([X_tab_valid.values, X_image])\n",
        "\n",
        "    print(\n",
        "        f\"Image dataset: {X_combined.shape[0]} samples, \"\n",
        "        f\"{X_tab_valid.shape[1]} tabular + {X_image.shape[1]} image features\"\n",
        "    )\n",
        "    print(\"Class counts:\\n\", y_valid.value_counts())\n",
        "    return X_combined, y_valid, {\n",
        "        \"tabular_features\": feature_cols,\n",
        "        \"n_tabular\": X_tab_valid.shape[1],\n",
        "        \"n_image\": X_image.shape[1],\n",
        "    }\n",
        "\n",
        "\n",
        "X_image_all, y_image_all, image_feature_info = build_image_dataset(df_raw)\n",
        "\n",
        "X_train_img, X_test_img, y_train_img, y_test_img = train_test_split(\n",
        "    X_image_all,\n",
        "    y_image_all,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y_image_all,\n",
        ")\n",
        "\n",
        "print(f\"Train/Test split sizes (image workflow): {len(X_train_img)} / {len(X_test_img)}\")\n",
        "\n",
        "image_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid_tabular,  # reuse same hyper-grid\n",
        "    cv=cv,\n",
        "    scoring=\"accuracy\",\n",
        "    n_jobs=1,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "image_search.fit(X_train_img, y_train_img)\n",
        "print(f\"Best params (image workflow): {image_search.best_params_}\")\n",
        "print(f\"Mean CV accuracy: {image_search.best_score_:.4f}\")\n",
        "\n",
        "best_image_model = image_search.best_estimator_\n",
        "cv_scores_img = cross_val_score(best_image_model, X_train_img, y_train_img, cv=cv, scoring=\"accuracy\")\n",
        "print(f\"CV mean ± 2*std: {cv_scores_img.mean():.4f} ± {2 * cv_scores_img.std():.4f}\")\n",
        "\n",
        "y_pred_img = best_image_model.predict(X_test_img)\n",
        "print(f\"Test accuracy: {accuracy_score(y_test_img, y_pred_img):.4f}\")\n",
        "print(\"Confusion matrix (test):\")\n",
        "print(confusion_matrix(y_test_img, y_pred_img))\n",
        "print(\"\\nClassification report (test):\")\n",
        "print(classification_report(y_test_img, y_pred_img, digits=4))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
